{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saved_models/Random Forest/rf_model.pkl', 'rb') as file:\n",
    "        rf_model = pickle.load(file)\n",
    "\n",
    "with open('./saved_models/XGBoost/xgb_model.pkl', 'rb') as f:\n",
    "        xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import preprocess\n",
    "importlib.reload(preprocess)\n",
    "from preprocess import Preprocessor\n",
    "\n",
    "\n",
    "with open(\"./saved_scalers/stdscaler.pkl\", 'rb') as file:\n",
    "        saved_scaler = pickle.load(file)\n",
    "\n",
    "with open(\"./saved_models/PCA/pca_model.pkl\", 'rb') as file:\n",
    "        saved_pca = pickle.load(file)\n",
    "\n",
    "p = Preprocessor(saved_std=saved_scaler)\n",
    "pca = saved_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "raw_test = pd.read_table(\"../Data/test_FD001.txt\", sep=' ', header=None)\n",
    "rul_values = pd.read_table(\"../Data/RUL_FD001.txt\", names=['remaining_cycles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remaining_cycles    100\n",
       "unit                100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading remaining cycles values\n",
    "rul_values['unit']=rul_values.index+1\n",
    "rul_values.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting current cycle values\n",
    "raw_test_copy = raw_test.copy()\n",
    "raw_test_copy.columns = [\"unit\", 'current_cycle'] + [f\"{i}\" for i in range(2, raw_test_copy.shape[1])]\n",
    "current_cycle = raw_test_copy.groupby('unit').max().iloc[:,:1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating maximum cycles\n",
    "max_cycle = rul_values.merge(current_cycle, on= 'unit', how='left')\n",
    "max_cycle['max_cycle'] =  max_cycle['current_cycle'] + max_cycle['remaining_cycles']\n",
    "max_cycle = max_cycle[['unit', 'max_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating rul = max cycles - current cycle\n",
    "raw_test_copy['max_cycle'] = raw_test_copy.merge(max_cycle, on='unit', how='left')['max_cycle']\n",
    "raw_test_copy['rul'] = raw_test_copy['max_cycle'] - raw_test_copy['current_cycle']\n",
    "y_test = np.log1p(raw_test_copy['rul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"rename columns\", FunctionTransformer(p.rename_columns, validate=False)),\n",
    "    (\"drop na\", FunctionTransformer(p.dropna)),\n",
    "    (\"drop no info columns\", FunctionTransformer(p.drop_no_info_cols)),\n",
    "    (\"dropping unit column\", FunctionTransformer(p.drop_unit)),\n",
    "    (\"updating col groups\", FunctionTransformer(p.update_col_groups)),    # returns the df from prev step\n",
    "    (\"Standardizing data\", FunctionTransformer(p.standardize_predictors, kw_args={'cols':['cycles']+p.get_sensor_cols()+p.get_op_setting_cols()})),\n",
    "    (\"performing PCA(1)\", pca)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_test = preprocessing_pipeline.fit_transform(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Test results:\n",
      "Root Mean Squared Error: 122.42930119401544\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf_model.predict(processed_X_test)\n",
    "mse = mean_squared_error(y_test, rf_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Random Forest Model Test results:\")\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Test results:\n",
      "Root Mean Squared Error: 120.80264180306887\n"
     ]
    }
   ],
   "source": [
    "xgb_pred = xgb_model.predict(processed_X_test)\n",
    "mse = mean_squared_error(y_test, xgb_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, xgb_pred)\n",
    "\n",
    "print(\"XGBoost Model Test results:\")\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictive_manintenance_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
