{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from neuralnetworks import DynamicSeqRegNN, RegressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saved_models/Random Forest/rf_model.pkl', 'rb') as file:\n",
    "        rf_model = pickle.load(file)\n",
    "\n",
    "with open('./saved_models/XGBoost/xgb_model.pkl', 'rb') as f:\n",
    "        xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data operations Loading data\n",
    "test = pd.read_table(\"../Data/test_FD001.txt\", sep=' ', header=None)\n",
    "\n",
    "p.rename_columns(train)\n",
    "train = train.dropna(axis=1, how='all')\n",
    "train = p.drop_no_info_cols(train)\n",
    "train = p.create_rul_col(train)\n",
    "sensor_cols, op_setting_cols, other_cols = p.update_col_groups(train)\n",
    "train_norm = p.normalize(train, sensor_cols + op_setting_cols)\n",
    "pca.fit(train_norm[predicting_cols])\n",
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline([\n",
    "    \n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictive_manintenance_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
